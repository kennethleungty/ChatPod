{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWw5wxvOseAK"
   },
   "source": [
    "# Chat Podcast\n",
    "\n",
    "Author: Kenneth Leung\n",
    "\n",
    "## 02. Whisper Transcription\n",
    "- Use Whisper audio-to-text capabilities to transcribe MP3 audio files of podcasts\n",
    "\n",
    "___\n",
    "**Note:** Highly recommended to open and run this notebook in Colab (use GPU runtime) ![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NylBITtPsg6d"
   },
   "source": [
    "## (1) Mount Drive in Colab\n",
    "- Faster way to get audio files accessible, as compared to uploading them to Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AlMr2cLGrfW5",
    "outputId": "e88ac547-5549-489a-9c4e-d2978967e34d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount Google drive (since MP3 files are saved in Drive)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UU_qO9fery5s",
    "outputId": "25ff1ce8-355f-4e04-f978-86a069622615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Data Vault/GitHub/Chat-Podcast\n"
     ]
    }
   ],
   "source": [
    "%cd drive/MyDrive/Data Vault/GitHub/Chat-Podcast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxYp1BiVskb8"
   },
   "source": [
    "___\n",
    "## (2) Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXjWEkuQoJMA",
    "outputId": "35c98085-29a1-40b5-9ab7-4e4a62a0ea21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.9/dist-packages (0.0.127)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.4.47)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.10.7)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.9/dist-packages (from langchain) (2.27.1)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.9/dist-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.22.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.9/dist-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.9/dist-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.9/dist-packages (0.27.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.9/dist-packages (20230314)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (0.56.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (4.65.0)\n",
      "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (0.2.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (1.13.1+cu116)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (1.22.4)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (9.1.0)\n",
      "Requirement already satisfied: tiktoken==0.3.1 in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (0.3.1)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (2.0.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python==0.2.0->openai-whisper) (0.18.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper) (2.27.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper) (2022.10.31)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper) (16.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper) (3.25.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper) (3.10.7)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper) (67.6.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper) (0.39.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2022.12.7)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.9/dist-packages (1.0.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pinecone-client\n",
      "  Downloading pinecone_client-2.2.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 KB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.9/dist-packages (from pinecone-client) (4.5.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from pinecone-client) (2.27.1)\n",
      "Collecting dnspython>=2.0.0\n",
      "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 KB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from pinecone-client) (1.26.15)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pinecone-client) (1.22.4)\n",
      "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.9/dist-packages (from pinecone-client) (6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.9/dist-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.9/dist-packages (from pinecone-client) (4.65.0)\n",
      "Collecting loguru>=0.5.0\n",
      "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pinecone-client) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pinecone-client) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
      "Installing collected packages: loguru, dnspython, pinecone-client\n",
      "Successfully installed dnspython-2.3.0 loguru-0.6.0 pinecone-client-2.2.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchain\n",
    "# !pip install openai\n",
    "# !pip install -U openai-whisper\n",
    "# !pip install python-dotenv\n",
    "# !pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "42re6SF_pLzW"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import whisper\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxYp1BiVskb8"
   },
   "source": [
    "___\n",
    "## (3) Configuration Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "ybGXi02qq8Vx",
    "outputId": "3879206c-6b3c-40e6-e203-caa7bbb96acb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'1.13.1+cu116'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch. __version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "FHVxuHYEqla_",
    "outputId": "7adb33b2-b6e1-45f6-9d4e-64fb74be8713"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qVzJFzw_rhMQ"
   },
   "outputs": [],
   "source": [
    "# Config settings\n",
    "DEMO_PATH = 'demo'\n",
    "AUDIO_PATH = 'audio'\n",
    "TRANSCRIPT_PATH = 'transcripts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = 'your_key_here'\n",
    "# load_dotenv(dotenv_path='.env', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPANnqPWqmF_"
   },
   "source": [
    "___\n",
    "## (4) Initial Demo Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "briwhNu8o82c"
   },
   "outputs": [],
   "source": [
    "whisper_model = whisper.load_model(\"medium.en\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "C2Z1HibLuC8T",
    "outputId": "8005dd3c-7b08-47af-a4ad-2040e9397d73"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\" I don't know who you are. I don't know what you want. If you are looking for ransom, I can tell you I don't have money. But what I do have are a very particular set of skills. Skills I have acquired over a very long career. Skills that make me a nightmare for people like you. If you let my daughter go now, that will be the end of it. I will not look for you. I will not pursue you. But if you don't, I will look for you. I will find you. And I will kill you. Good luck.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = whisper_model.transcribe(f\"{DEMO_PATH}/Liam Neeson - Taken.mp3\")\n",
    "text['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_B3LXkKetod2"
   },
   "source": [
    "___\n",
    "## (5) Transcribe All Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3cjDCFOfxtir"
   },
   "outputs": [],
   "source": [
    "# Load podcast metadata (generated from notebook 01)\n",
    "metadata = pd.read_csv('podcast_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xVW3j5W3W8p",
    "outputId": "1635bfa8-a95a-4851-9bf2-72a44cf67e87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"audio/A Third Path to Talent Development - Delta's Michelle McCrackin.mp3\",\n",
       " \"audio/AI in Aerospace - Boeing's Helen Lee.mp3\",\n",
       " \"audio/AI in Your Living Room - Peloton's Sanjay Nichani.mp3\",\n",
       " \"audio/Big Data in Agriculture - Land O'Lakes' Teddy Bekele.mp3\",\n",
       " \"audio/Choreographing Human-Machine Collaboration - Spotify's Sidney Madison Prescott.mp3\",\n",
       " \"audio/Digital First, Physical Second - Wayfair's Fiona Tan.mp3\",\n",
       " \"audio/Extreme Innovation with AI - Stanley Black and Decker's Mark Maybury.mp3\",\n",
       " \"audio/From Data to Wisdom - Novo Nordisk's Tonia Sideri.mp3\",\n",
       " \"audio/From Journalism to Jeans - Levi Strauss' Katia Walsh.mp3\",\n",
       " \"audio/Helping Doctors Make Better Decisions with Data - UC Berkley's Ziad Obermeyer.mp3\",\n",
       " \"audio/Imagining Furniture (and the Future) with AI - IKEA Retail's Barbara Martin Coppola.mp3\",\n",
       " \"audio/Inventing the Beauty of the Future - L'Oreal's Stephane Lannuzel.mp3\",\n",
       " \"audio/Investing in the Last Mile - PayPal's Khatereh Khodavirdi.mp3\",\n",
       " \"audio/Keeping Humans in the (Feedback) Loop - Orangetheory Fitness' Ameen Kazerouni.mp3\",\n",
       " \"audio/Out of the Lab and Into a Product - Microsoft's Eric Boyd.mp3\",\n",
       " \"audio/Precision Medicine in Pharma - Sanofi's Frank Nestle.mp3\",\n",
       " \"audio/The Beauty of AI - Estee Lauder's Sowmya Gottipati.mp3\",\n",
       " \"audio/The Collaboration Muscle - LinkedIn's Ya Xu.mp3\",\n",
       " \"audio/The Three Roles of the Chief Data Officer - ADP's Jack Berkowitz.mp3\",\n",
       " \"audio/Transforming Transactions with Technology - eBay's Nitzan Mekel-Bobrov.mp3\",\n",
       " \"audio/Transforming a Technology Organization for the Future - Starbucks' Gerri Martin-Flickinger.mp3\",\n",
       " \"audio/Turning Sound Into Information - Warner Music Group's Kobi Abayomi.mp3\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = sorted([str(x) for x in Path(AUDIO_PATH).glob('*.mp3')])\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDyTJUey6dn7"
   },
   "outputs": [],
   "source": [
    "# Save each transcript as JSON Line file\n",
    "def save_transcript_json(content, title):\n",
    "    with open(f\"transcripts/{title}.jsonl\", \"w\", encoding=\"utf-8\") as fp:\n",
    "        for line in content:\n",
    "            json.dump(line, fp)\n",
    "            fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ArS906GHyb2o",
    "outputId": "4137761d-0624-4c42-9e01-84c09f16a3fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript already exists for A Third Path to Talent Development - Delta's Michelle McCrackin. Skipping\n",
      "Transcript already exists for AI in Aerospace - Boeing's Helen Lee. Skipping\n",
      "Begin transcription for AI in Your Living Room - Peloton's Sanjay Nichani\n",
      "2.9641833583513897 minutes taken for episode: AI in Your Living Room - Peloton's Sanjay Nichani\n",
      "Begin transcription for Big Data in Agriculture - Land O'Lakes' Teddy Bekele\n",
      "3.1866719404856365 minutes taken for episode: Big Data in Agriculture - Land O'Lakes' Teddy Bekele\n",
      "Begin transcription for Choreographing Human-Machine Collaboration - Spotify's Sidney Madison Prescott\n",
      "4.17211240530014 minutes taken for episode: Choreographing Human-Machine Collaboration - Spotify's Sidney Madison Prescott\n",
      "Begin transcription for Digital First, Physical Second - Wayfair's Fiona Tan\n",
      "3.555857837200165 minutes taken for episode: Digital First, Physical Second - Wayfair's Fiona Tan\n",
      "Begin transcription for Extreme Innovation with AI - Stanley Black and Decker's Mark Maybury\n",
      "4.794457908471426 minutes taken for episode: Extreme Innovation with AI - Stanley Black and Decker's Mark Maybury\n",
      "Begin transcription for From Data to Wisdom - Novo Nordisk's Tonia Sideri\n",
      "3.4712600072224933 minutes taken for episode: From Data to Wisdom - Novo Nordisk's Tonia Sideri\n",
      "Begin transcription for From Journalism to Jeans - Levi Strauss' Katia Walsh\n",
      "3.619757397969564 minutes taken for episode: From Journalism to Jeans - Levi Strauss' Katia Walsh\n",
      "Begin transcription for Helping Doctors Make Better Decisions with Data - UC Berkley's Ziad Obermeyer\n",
      "4.458520710468292 minutes taken for episode: Helping Doctors Make Better Decisions with Data - UC Berkley's Ziad Obermeyer\n",
      "Begin transcription for Imagining Furniture (and the Future) with AI - IKEA Retail's Barbara Martin Coppola\n",
      "3.594948967297872 minutes taken for episode: Imagining Furniture (and the Future) with AI - IKEA Retail's Barbara Martin Coppola\n",
      "Begin transcription for Inventing the Beauty of the Future - L'Oreal's Stephane Lannuzel\n",
      "2.334605924288432 minutes taken for episode: Inventing the Beauty of the Future - L'Oreal's Stephane Lannuzel\n",
      "Begin transcription for Investing in the Last Mile - PayPal's Khatereh Khodavirdi\n",
      "3.786522392431895 minutes taken for episode: Investing in the Last Mile - PayPal's Khatereh Khodavirdi\n",
      "Begin transcription for Keeping Humans in the (Feedback) Loop - Orangetheory Fitness' Ameen Kazerouni\n",
      "3.016189650694529 minutes taken for episode: Keeping Humans in the (Feedback) Loop - Orangetheory Fitness' Ameen Kazerouni\n",
      "Begin transcription for Out of the Lab and Into a Product - Microsoft's Eric Boyd\n",
      "4.744445196787516 minutes taken for episode: Out of the Lab and Into a Product - Microsoft's Eric Boyd\n",
      "Begin transcription for Precision Medicine in Pharma - Sanofi's Frank Nestle\n",
      "3.310854804515839 minutes taken for episode: Precision Medicine in Pharma - Sanofi's Frank Nestle\n",
      "Begin transcription for The Beauty of AI - Estee Lauder's Sowmya Gottipati\n",
      "2.767304786046346 minutes taken for episode: The Beauty of AI - Estee Lauder's Sowmya Gottipati\n",
      "Begin transcription for The Collaboration Muscle - LinkedIn's Ya Xu\n",
      "3.680276024341583 minutes taken for episode: The Collaboration Muscle - LinkedIn's Ya Xu\n",
      "Begin transcription for The Three Roles of the Chief Data Officer - ADP's Jack Berkowitz\n",
      "2.9918702562650044 minutes taken for episode: The Three Roles of the Chief Data Officer - ADP's Jack Berkowitz\n",
      "Begin transcription for Transforming Transactions with Technology - eBay's Nitzan Mekel-Bobrov\n",
      "3.0016634662946067 minutes taken for episode: Transforming Transactions with Technology - eBay's Nitzan Mekel-Bobrov\n",
      "Begin transcription for Transforming a Technology Organization for the Future - Starbucks' Gerri Martin-Flickinger\n",
      "3.8846916874249775 minutes taken for episode: Transforming a Technology Organization for the Future - Starbucks' Gerri Martin-Flickinger\n",
      "Begin transcription for Turning Sound Into Information - Warner Music Group's Kobi Abayomi\n",
      "3.6656936526298525 minutes taken for episode: Turning Sound Into Information - Warner Music Group's Kobi Abayomi\n"
     ]
    }
   ],
   "source": [
    "# Transcribe every MP3 file in audio folder\n",
    "for i, path in enumerate(paths):\n",
    "    episode_content = []\n",
    "\n",
    "    # Get info of podcast episode\n",
    "    title = path.split('/')[-1][:-4]\n",
    "\n",
    "    # Skip if transcript already exists\n",
    "    existing_transcripts = [str(x).split('/')[-1].split('.')[0] for x in \\\n",
    "                            Path(TRANSCRIPTS_PATH).glob('*')]\n",
    "    if title in existing_transcripts:\n",
    "        print(f'Transcript already exists for {title}. Skipping')\n",
    "    else:\n",
    "        date = metadata[metadata.Title == title][\"Date\"].values[0]\n",
    "        url = metadata[metadata.Title == title][\"URL\"].values[0]\n",
    "      \n",
    "        # Initiate timer\n",
    "        print(f'Begin transcription for {title}')\n",
    "        start = time.time()\n",
    "\n",
    "        # Transcribe MP3 audio with Whisper\n",
    "        result = whisper_model.transcribe(path)\n",
    "        segments = result['segments']\n",
    "\n",
    "        for segment in segments:\n",
    "            # Merge segments data and podcast metadata\n",
    "            segment_content = {'title': title,\n",
    "                               'date': date,\n",
    "                               'url': url,\n",
    "                               'id': f\"{title}-t{segment['start']}\",\n",
    "                               'text': segment['text'].strip(),\n",
    "                               'start': segment['start'],\n",
    "                               'end': segment['end']}\n",
    "            episode_content.append(segment_content)\n",
    "\n",
    "        # Save contents as JSON\n",
    "        save_transcript_json(episode_content, title)\n",
    "      \n",
    "        # Show time taken\n",
    "        duration = time.time() -start\n",
    "        print(f\"{duration/60} minutes taken for episode: {title}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
