{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWw5wxvOseAK"
   },
   "source": [
    "# Chat Podcast\n",
    "\n",
    "Author: Kenneth Leung\n",
    "\n",
    "## 02. Whisper Transcription and Pinecone Build\n",
    "- Use Whisper audio-to-text capabilities to transcribe MP3 audio files of podcasts\n",
    "- Use Pinecone to build vectorstores of transcripts\n",
    "\n",
    "___\n",
    "**Note:** Highly recommended to open and run this notebook in Colab (use GPU runtime) ![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NylBITtPsg6d"
   },
   "source": [
    "## (1) Mount Drive in Colab\n",
    "- Faster way to get audio files accessible, as compared to uploading them to Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AlMr2cLGrfW5",
    "outputId": "e88ac547-5549-489a-9c4e-d2978967e34d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount Google drive (since MP3 files are saved in Drive)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UU_qO9fery5s",
    "outputId": "25ff1ce8-355f-4e04-f978-86a069622615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Data Vault/GitHub/Chat-Podcast\n"
     ]
    }
   ],
   "source": [
    "%cd drive/MyDrive/Data Vault/GitHub/Chat-Podcast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxYp1BiVskb8"
   },
   "source": [
    "___\n",
    "## (2) Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXjWEkuQoJMA",
    "outputId": "35c98085-29a1-40b5-9ab7-4e4a62a0ea21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.9/dist-packages (0.0.127)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.4.47)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.10.7)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.9/dist-packages (from langchain) (2.27.1)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.9/dist-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.22.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.9/dist-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.9/dist-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.9/dist-packages (0.27.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.9/dist-packages (20230314)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (0.56.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (4.65.0)\n",
      "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (0.2.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (1.13.1+cu116)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (1.22.4)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (9.1.0)\n",
      "Requirement already satisfied: tiktoken==0.3.1 in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (0.3.1)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (2.0.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python==0.2.0->openai-whisper) (0.18.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper) (2.27.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper) (2022.10.31)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper) (16.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper) (3.25.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper) (3.10.7)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper) (67.6.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper) (0.39.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2022.12.7)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.9/dist-packages (1.0.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pinecone-client\n",
      "  Downloading pinecone_client-2.2.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 KB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.9/dist-packages (from pinecone-client) (4.5.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from pinecone-client) (2.27.1)\n",
      "Collecting dnspython>=2.0.0\n",
      "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 KB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from pinecone-client) (1.26.15)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pinecone-client) (1.22.4)\n",
      "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.9/dist-packages (from pinecone-client) (6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.9/dist-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.9/dist-packages (from pinecone-client) (4.65.0)\n",
      "Collecting loguru>=0.5.0\n",
      "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pinecone-client) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pinecone-client) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
      "Installing collected packages: loguru, dnspython, pinecone-client\n",
      "Successfully installed dnspython-2.3.0 loguru-0.6.0 pinecone-client-2.2.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchain\n",
    "# !pip install openai\n",
    "# !pip install -U openai-whisper\n",
    "# !pip install python-dotenv\n",
    "# !pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "42re6SF_pLzW"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import pinecone\n",
    "import time\n",
    "import torch\n",
    "import whisper\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxYp1BiVskb8"
   },
   "source": [
    "___\n",
    "## (3) Configuration Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "ybGXi02qq8Vx",
    "outputId": "3879206c-6b3c-40e6-e203-caa7bbb96acb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'1.13.1+cu116'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch. __version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "FHVxuHYEqla_",
    "outputId": "7adb33b2-b6e1-45f6-9d4e-64fb74be8713"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qVzJFzw_rhMQ"
   },
   "outputs": [],
   "source": [
    "# Config settings\n",
    "DEMO_PATH = 'demo'\n",
    "AUDIO_PATH = 'audio'\n",
    "TRANSCRIPT_PATH = 'transcripts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPANnqPWqmF_"
   },
   "source": [
    "___\n",
    "## (4) Initial Demo Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "briwhNu8o82c"
   },
   "outputs": [],
   "source": [
    "whisper_model = whisper.load_model(\"medium.en\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "C2Z1HibLuC8T",
    "outputId": "8005dd3c-7b08-47af-a4ad-2040e9397d73"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\" I don't know who you are. I don't know what you want. If you are looking for ransom, I can tell you I don't have money. But what I do have are a very particular set of skills. Skills I have acquired over a very long career. Skills that make me a nightmare for people like you. If you let my daughter go now, that will be the end of it. I will not look for you. I will not pursue you. But if you don't, I will look for you. I will find you. And I will kill you. Good luck.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = whisper_model.transcribe(f\"{DEMO_PATH}/Liam Neeson - Taken.mp3\")\n",
    "text['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_B3LXkKetod2"
   },
   "source": [
    "___\n",
    "## (5) Transcribe All Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3cjDCFOfxtir"
   },
   "outputs": [],
   "source": [
    "# Load podcast metadata (generated from notebook 01)\n",
    "metadata = pd.read_csv('podcast_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xVW3j5W3W8p",
    "outputId": "1635bfa8-a95a-4851-9bf2-72a44cf67e87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"audio/A Third Path to Talent Development - Delta's Michelle McCrackin.mp3\",\n",
       " \"audio/AI in Aerospace - Boeing's Helen Lee.mp3\",\n",
       " \"audio/AI in Your Living Room - Peloton's Sanjay Nichani.mp3\",\n",
       " \"audio/Big Data in Agriculture - Land O'Lakes' Teddy Bekele.mp3\",\n",
       " \"audio/Choreographing Human-Machine Collaboration - Spotify's Sidney Madison Prescott.mp3\",\n",
       " \"audio/Digital First, Physical Second - Wayfair's Fiona Tan.mp3\",\n",
       " \"audio/Extreme Innovation with AI - Stanley Black and Decker's Mark Maybury.mp3\",\n",
       " \"audio/From Data to Wisdom - Novo Nordisk's Tonia Sideri.mp3\",\n",
       " \"audio/From Journalism to Jeans - Levi Strauss' Katia Walsh.mp3\",\n",
       " \"audio/Helping Doctors Make Better Decisions with Data - UC Berkley's Ziad Obermeyer.mp3\",\n",
       " \"audio/Imagining Furniture (and the Future) with AI - IKEA Retail's Barbara Martin Coppola.mp3\",\n",
       " \"audio/Inventing the Beauty of the Future - L'Oreal's Stephane Lannuzel.mp3\",\n",
       " \"audio/Investing in the Last Mile - PayPal's Khatereh Khodavirdi.mp3\",\n",
       " \"audio/Keeping Humans in the (Feedback) Loop - Orangetheory Fitness' Ameen Kazerouni.mp3\",\n",
       " \"audio/Out of the Lab and Into a Product - Microsoft's Eric Boyd.mp3\",\n",
       " \"audio/Precision Medicine in Pharma - Sanofi's Frank Nestle.mp3\",\n",
       " \"audio/The Beauty of AI - Estee Lauder's Sowmya Gottipati.mp3\",\n",
       " \"audio/The Collaboration Muscle - LinkedIn's Ya Xu.mp3\",\n",
       " \"audio/The Three Roles of the Chief Data Officer - ADP's Jack Berkowitz.mp3\",\n",
       " \"audio/Transforming Transactions with Technology - eBay's Nitzan Mekel-Bobrov.mp3\",\n",
       " \"audio/Transforming a Technology Organization for the Future - Starbucks' Gerri Martin-Flickinger.mp3\",\n",
       " \"audio/Turning Sound Into Information - Warner Music Group's Kobi Abayomi.mp3\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = sorted([str(x) for x in Path(AUDIO_PATH).glob('*.mp3')])\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDyTJUey6dn7"
   },
   "outputs": [],
   "source": [
    "# Save each transcript as JSON Line file\n",
    "def save_transcript_json(content, title):\n",
    "    with open(f\"transcripts/{title}.jsonl\", \"w\", encoding=\"utf-8\") as fp:\n",
    "        for line in content:\n",
    "            json.dump(line, fp)\n",
    "            fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ArS906GHyb2o",
    "outputId": "4137761d-0624-4c42-9e01-84c09f16a3fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript already exists for A Third Path to Talent Development - Delta's Michelle McCrackin. Skipping\n",
      "Transcript already exists for AI in Aerospace - Boeing's Helen Lee. Skipping\n",
      "Begin transcription for AI in Your Living Room - Peloton's Sanjay Nichani\n",
      "2.9641833583513897 minutes taken for episode: AI in Your Living Room - Peloton's Sanjay Nichani\n",
      "Begin transcription for Big Data in Agriculture - Land O'Lakes' Teddy Bekele\n",
      "3.1866719404856365 minutes taken for episode: Big Data in Agriculture - Land O'Lakes' Teddy Bekele\n",
      "Begin transcription for Choreographing Human-Machine Collaboration - Spotify's Sidney Madison Prescott\n",
      "4.17211240530014 minutes taken for episode: Choreographing Human-Machine Collaboration - Spotify's Sidney Madison Prescott\n",
      "Begin transcription for Digital First, Physical Second - Wayfair's Fiona Tan\n",
      "3.555857837200165 minutes taken for episode: Digital First, Physical Second - Wayfair's Fiona Tan\n",
      "Begin transcription for Extreme Innovation with AI - Stanley Black and Decker's Mark Maybury\n",
      "4.794457908471426 minutes taken for episode: Extreme Innovation with AI - Stanley Black and Decker's Mark Maybury\n",
      "Begin transcription for From Data to Wisdom - Novo Nordisk's Tonia Sideri\n",
      "3.4712600072224933 minutes taken for episode: From Data to Wisdom - Novo Nordisk's Tonia Sideri\n",
      "Begin transcription for From Journalism to Jeans - Levi Strauss' Katia Walsh\n",
      "3.619757397969564 minutes taken for episode: From Journalism to Jeans - Levi Strauss' Katia Walsh\n",
      "Begin transcription for Helping Doctors Make Better Decisions with Data - UC Berkley's Ziad Obermeyer\n",
      "4.458520710468292 minutes taken for episode: Helping Doctors Make Better Decisions with Data - UC Berkley's Ziad Obermeyer\n",
      "Begin transcription for Imagining Furniture (and the Future) with AI - IKEA Retail's Barbara Martin Coppola\n",
      "3.594948967297872 minutes taken for episode: Imagining Furniture (and the Future) with AI - IKEA Retail's Barbara Martin Coppola\n",
      "Begin transcription for Inventing the Beauty of the Future - L'Oreal's Stephane Lannuzel\n",
      "2.334605924288432 minutes taken for episode: Inventing the Beauty of the Future - L'Oreal's Stephane Lannuzel\n",
      "Begin transcription for Investing in the Last Mile - PayPal's Khatereh Khodavirdi\n",
      "3.786522392431895 minutes taken for episode: Investing in the Last Mile - PayPal's Khatereh Khodavirdi\n",
      "Begin transcription for Keeping Humans in the (Feedback) Loop - Orangetheory Fitness' Ameen Kazerouni\n",
      "3.016189650694529 minutes taken for episode: Keeping Humans in the (Feedback) Loop - Orangetheory Fitness' Ameen Kazerouni\n",
      "Begin transcription for Out of the Lab and Into a Product - Microsoft's Eric Boyd\n",
      "4.744445196787516 minutes taken for episode: Out of the Lab and Into a Product - Microsoft's Eric Boyd\n",
      "Begin transcription for Precision Medicine in Pharma - Sanofi's Frank Nestle\n",
      "3.310854804515839 minutes taken for episode: Precision Medicine in Pharma - Sanofi's Frank Nestle\n",
      "Begin transcription for The Beauty of AI - Estee Lauder's Sowmya Gottipati\n",
      "2.767304786046346 minutes taken for episode: The Beauty of AI - Estee Lauder's Sowmya Gottipati\n",
      "Begin transcription for The Collaboration Muscle - LinkedIn's Ya Xu\n",
      "3.680276024341583 minutes taken for episode: The Collaboration Muscle - LinkedIn's Ya Xu\n",
      "Begin transcription for The Three Roles of the Chief Data Officer - ADP's Jack Berkowitz\n",
      "2.9918702562650044 minutes taken for episode: The Three Roles of the Chief Data Officer - ADP's Jack Berkowitz\n",
      "Begin transcription for Transforming Transactions with Technology - eBay's Nitzan Mekel-Bobrov\n",
      "3.0016634662946067 minutes taken for episode: Transforming Transactions with Technology - eBay's Nitzan Mekel-Bobrov\n",
      "Begin transcription for Transforming a Technology Organization for the Future - Starbucks' Gerri Martin-Flickinger\n",
      "3.8846916874249775 minutes taken for episode: Transforming a Technology Organization for the Future - Starbucks' Gerri Martin-Flickinger\n",
      "Begin transcription for Turning Sound Into Information - Warner Music Group's Kobi Abayomi\n",
      "3.6656936526298525 minutes taken for episode: Turning Sound Into Information - Warner Music Group's Kobi Abayomi\n"
     ]
    }
   ],
   "source": [
    "# Transcribe every MP3 file in audio folder\n",
    "for i, path in enumerate(paths):\n",
    "    episode_content = []\n",
    "\n",
    "    # Get info of podcast episode\n",
    "    title = path.split('/')[-1][:-4]\n",
    "\n",
    "    # Skip if transcript already exists\n",
    "    existing_transcripts = [str(x).split('/')[-1].split('.')[0] for x in \\\n",
    "                            Path(TRANSCRIPTS_PATH).glob('*')]\n",
    "    if title in existing_transcripts:\n",
    "        print(f'Transcript already exists for {title}. Skipping')\n",
    "    else:\n",
    "        date = metadata[metadata.Title == title][\"Date\"].values[0]\n",
    "        url = metadata[metadata.Title == title][\"URL\"].values[0]\n",
    "      \n",
    "        # Initiate timer\n",
    "        print(f'Begin transcription for {title}')\n",
    "        start = time.time()\n",
    "\n",
    "        # Transcribe MP3 audio with Whisper\n",
    "        result = whisper_model.transcribe(path)\n",
    "        segments = result['segments']\n",
    "\n",
    "        for segment in segments:\n",
    "            # Merge segments data and podcast metadata\n",
    "            segment_content = {'title': title,\n",
    "                               'date': date,\n",
    "                               'url': url,\n",
    "                               'id': f\"{title}-t{segment['start']}\",\n",
    "                               'text': segment['text'].strip(),\n",
    "                               'start': segment['start'],\n",
    "                               'end': segment['end']}\n",
    "            episode_content.append(segment_content)\n",
    "\n",
    "        # Save contents as JSON\n",
    "        save_transcript_json(episode_content, title)\n",
    "      \n",
    "        # Show time taken\n",
    "        duration = time.time() -start\n",
    "        print(f\"{duration/60} minutes taken for episode: {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_B3LXkKetod2"
   },
   "source": [
    "___\n",
    "## (6) Post-Processing of Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YPKjSLtWyb0Q",
    "outputId": "ef0817c2-fd2c-424d-d622-84f5b05d1392",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"transcripts/A Third Path to Talent Development - Delta's Michelle McCrackin.jsonl\",\n",
       " \"transcripts/AI in Aerospace - Boeing's Helen Lee.jsonl\",\n",
       " \"transcripts/AI in Your Living Room - Peloton's Sanjay Nichani.jsonl\",\n",
       " \"transcripts/Big Data in Agriculture - Land O'Lakes' Teddy Bekele.jsonl\",\n",
       " \"transcripts/Choreographing Human-Machine Collaboration - Spotify's Sidney Madison Prescott.jsonl\",\n",
       " \"transcripts/Digital First, Physical Second - Wayfair's Fiona Tan.jsonl\",\n",
       " \"transcripts/Extreme Innovation with AI - Stanley Black and Decker's Mark Maybury.jsonl\",\n",
       " \"transcripts/From Data to Wisdom - Novo Nordisk's Tonia Sideri.jsonl\",\n",
       " \"transcripts/From Journalism to Jeans - Levi Strauss' Katia Walsh.jsonl\",\n",
       " \"transcripts/Helping Doctors Make Better Decisions with Data - UC Berkley's Ziad Obermeyer.jsonl\",\n",
       " \"transcripts/Imagining Furniture (and the Future) with AI - IKEA Retail's Barbara Martin Coppola.jsonl\",\n",
       " \"transcripts/Inventing the Beauty of the Future - L'Oreal's Stephane Lannuzel.jsonl\",\n",
       " \"transcripts/Investing in the Last Mile - PayPal's Khatereh Khodavirdi.jsonl\",\n",
       " \"transcripts/Keeping Humans in the (Feedback) Loop - Orangetheory Fitness' Ameen Kazerouni.jsonl\",\n",
       " \"transcripts/Out of the Lab and Into a Product - Microsoft's Eric Boyd.jsonl\",\n",
       " \"transcripts/Precision Medicine in Pharma - Sanofi's Frank Nestle.jsonl\",\n",
       " \"transcripts/The Beauty of AI - Estee Lauder's Sowmya Gottipati.jsonl\",\n",
       " \"transcripts/The Collaboration Muscle - LinkedIn's Ya Xu.jsonl\",\n",
       " \"transcripts/The Three Roles of the Chief Data Officer - ADP's Jack Berkowitz.jsonl\",\n",
       " \"transcripts/Transforming Transactions with Technology - eBay's Nitzan Mekel-Bobrov.jsonl\",\n",
       " \"transcripts/Transforming a Technology Organization for the Future - Starbucks' Gerri Martin-Flickinger.jsonl\",\n",
       " \"transcripts/Turning Sound Into Information - Warner Music Group's Kobi Abayomi.jsonl\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View all transcribed files\n",
    "transcripts = sorted([str(x) for x in Path(TRANSCRIPT_PATH).glob('*.jsonl')])\n",
    "transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1hf3gsSsvzh"
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "# Combine all JSONL files together\n",
    "for transcript in transcripts:\n",
    "    with open(transcript, \"r\", encoding=\"utf-8\") as fp:\n",
    "        for line in fp:\n",
    "            line = json.loads(line) # Convert string dictionary to dict\n",
    "            lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ehnMB0cBsvwr",
    "outputId": "f6222924-58c5-445f-b4e1-78672c2e405d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7152\n"
     ]
    }
   ],
   "source": [
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8GmBbj9gtvS9",
    "outputId": "7bd88050-e0b3-40b9-db4a-454419a6222e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': \"A Third Path to Talent Development - Delta's Michelle McCrackin\",\n",
       " 'date': 'Mar-23',\n",
       " 'url': 'https://open.spotify.com/episode/50oRprIC6z0wJkpfLFQHDi',\n",
       " 'id': \"A Third Path to Talent Development - Delta's Michelle McCrackin-t32.56\",\n",
       " 'text': \"I'm also the AI and Business Strategy guest editor at MIT Sloan Management Review.\",\n",
       " 'start': 32.56,\n",
       " 'end': 38.019999999999996}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WdwVo6z9vdTX",
    "outputId": "f7a2db08-2e94-4f92-a173-5fe55489cea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm Sam Ransbotham, Professor of Analytics at Boston College.\n",
      "I'm also the AI and Business Strategy guest editor at MIT Sloan Management Review.\n",
      "And I'm Shervin Kottubande, senior partner with BCG and one of the leaders of our AI business.\n"
     ]
    }
   ],
   "source": [
    "# Check text in every segment\n",
    "for chunk in lines[5:8]:\n",
    "    print(chunk['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## (7) Extend Segment Texts\n",
    "- We do not want each segment to be only one phrase/sentence long\n",
    "- To make the indexing more useful and logical, we combine the texts of multiple segments together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g2qtVLf_-_DF"
   },
   "outputs": [],
   "source": [
    "# Chunking and striding\n",
    "new_segments = []\n",
    "\n",
    "chunk_size = 6  # No. of segment texts to combine\n",
    "chunk_overlap = 3  # No. of segment texts to overlap\n",
    "\n",
    "for i in range(0, len(lines), chunk_overlap):\n",
    "    i_end = min(len(lines)-1, i + chunk_size)\n",
    "    if lines[i]['title'] != lines[i_end]['title']:\n",
    "        # Skip if audio file names are same\n",
    "        continue\n",
    "    text_list = []\n",
    "    for chunk in lines[i:i_end]:\n",
    "        text_list.append(chunk['text'])\n",
    "    text = ' '.join(text_list)\n",
    "    new_segments.append({\n",
    "        'start': lines[i]['start'],\n",
    "        'end': lines[i_end]['end'],\n",
    "        'title': lines[i]['title'],\n",
    "        'text': text,\n",
    "        'id': lines[i]['id'],\n",
    "        'url': lines[i]['url'],\n",
    "        'date': lines[i]['date']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-LAF21xhya22",
    "outputId": "6fc1ce11-0eb6-4038-988a-b6fc96237f43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2342"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfwulaHaycE_",
    "outputId": "066a5fcc-dbd3-4196-904b-b129e145a62a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 0.0,\n",
       " 'end': 38.019999999999996,\n",
       " 'title': \"A Third Path to Talent Development - Delta's Michelle McCrackin\",\n",
       " 'text': \"How can organizations take advantage of existing deep domain knowledge? Find out how one airline is upscaling its frontline workforce on today's episode. I'm Michelle McCracken from Delta Airlines and you're listening to Me, Myself and AI. Welcome to Me, Myself and AI, a podcast on artificial intelligence and business. Each episode we introduce you to someone innovating with AI. I'm Sam Ransbotham, Professor of Analytics at Boston College.\",\n",
       " 'id': \"A Third Path to Talent Development - Delta's Michelle McCrackin-t0.0\",\n",
       " 'url': 'https://open.spotify.com/episode/50oRprIC6z0wJkpfLFQHDi',\n",
       " 'date': 'Mar-23'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_segments[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## (8) Setup Vectorstore with Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ldz1NNkY_BAr"
   },
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZZ-PJwOSWbp",
    "outputId": "f47be6cc-5409-4a0e-a622-e3092609f65e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize pinecone instance\n",
    "pinecone.init(\n",
    "    api_key=os.environ['PINECONE_API_KEY'],\n",
    "    environment=os.environ['PINECONE_ENV'])\n",
    "\n",
    "index_name = \"chat-podcast\"\n",
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        1536, # Dimensions of OpenAI embeddings\n",
    "        metric=\"cosine\"\n",
    "    )\n",
    "\n",
    "index = pinecone.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l5YK8AceVSPE",
    "outputId": "07d9a793-fb22-4487-e4ff-99691df424c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 0.0,\n",
       " 'end': 38.019999999999996,\n",
       " 'title': \"A Third Path to Talent Development - Delta's Michelle McCrackin\",\n",
       " 'text': \"How can organizations take advantage of existing deep domain knowledge? Find out how one airline is upscaling its frontline workforce on today's episode. I'm Michelle McCracken from Delta Airlines and you're listening to Me, Myself and AI. Welcome to Me, Myself and AI, a podcast on artificial intelligence and business. Each episode we introduce you to someone innovating with AI. I'm Sam Ransbotham, Professor of Analytics at Boston College.\",\n",
       " 'id': \"A Third Path to Talent Development - Delta's Michelle McCrackin-t0.0\",\n",
       " 'url': 'https://open.spotify.com/episode/50oRprIC6z0wJkpfLFQHDi',\n",
       " 'date': 'Mar-23'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_segments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hlAcPyOUlYb"
   },
   "outputs": [],
   "source": [
    "# Convert segments into three lists for vectorstore upsert\n",
    "texts = [elem['text'] for elem in new_segments]\n",
    "ids = [elem['id'] for elem in new_segments]\n",
    "metadatas = [{\n",
    "            \"text\": elem[\"text\"],\n",
    "            \"start\": elem[\"start\"],\n",
    "            \"end\": elem[\"end\"],\n",
    "            \"url\": elem[\"url\"],\n",
    "            \"date\": elem[\"date\"],\n",
    "            \"title\": elem[\"title\"]\n",
    "            } for elem in new_segments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bniNtqzCUWU1"
   },
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_texts(texts=texts, \n",
    "                                embedding=embeddings, \n",
    "                                metadatas=metadatas,\n",
    "                                ids=ids,\n",
    "                                index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qbq7vO4jW7DM",
    "outputId": "7959243b-8383-4e31-d2d0-628529332250"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 2342}},\n",
       " 'total_vector_count': 2342}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## (9) Vector Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPMRZe1-1vG2"
   },
   "outputs": [],
   "source": [
    "query = \"Which guest was invited to talk about the airline industry?\"\n",
    "docs = docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfxeRLw4Xa3V",
    "outputId": "3dc4e848-3111-4d93-d9d2-806b6c128c44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shervin are excited to be talking today with Helen Li, Regional Director of Air Traffic Management and Airport Programs in China for the Boeing Company. Helen, thanks for taking the time to talk with us. Welcome. Thank you for having me. Let's get started. Helen, can you tell us about your current role at Boeing? I currently work at Boeing China in the Beijing office.\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CcwBwlQp_LzD"
   },
   "outputs": [],
   "source": [
    "# References\n",
    "# https://huggingface.co/openai/whisper-medium\n",
    "# https://github.com/hwchase17/langchain/blob/master/langchain/vectorstores/pinecone.py\n",
    "# https://www.pinecone.io/learn/openai-whisper/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
